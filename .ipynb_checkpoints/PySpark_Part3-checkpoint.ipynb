{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717b38ef",
   "metadata": {},
   "source": [
    "# Lesson Three : Clean Data with Pyspark\n",
    "### By Samuel Ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4420c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - The aim of this lesson is to explore the Data Transformation\n",
    "# - Learn how to drop table rows and columns\n",
    "# - Various Parameter in dropping functionalities\n",
    "# - Handling missing values by Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af4d4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe941f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "570c4e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session (spark is a variable)\n",
    "# for operation\n",
    "spark=SparkSession.builder.appName('dataTransformation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c83e2e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.2.85:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataTransformation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10592bdc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c13e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe\n",
    "df_spark=spark.read.csv('test3.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13378b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----------+------+\n",
      "|          Name| Age|      Qualification|Experience|Salary|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "|Kennith Kawaki|null|            Diploma|      null|  null|\n",
      "|   Sudans Wong|  31|         Apprentice|         6| 40000|\n",
      "|   Polly Combo|  27|            Diploma|         4| 35000|\n",
      "|Desmond Cheung|  51|University Graduate|        22| 88000|\n",
      "|     Chariotte|  35|            Diploma|         8| 61000|\n",
      "|        Sophia|null|         Apprentice|         3| 30000|\n",
      "|          null|  25|            Diploma|         3| 28000|\n",
      "|  George Woody|  31|               null|         7| 47000|\n",
      "|    Pansy Rose|  33|         Apprentice|      null|  null|\n",
      "|          John|  17|         Apprentice|         1| 24300|\n",
      "|         Peter|  45|University Graduate|        18| 81000|\n",
      "|         David|  42|University Graduate|        15| 76000|\n",
      "|        Usamha|  28|            Diploma|         4| 33000|\n",
      "|    Zain Amjun|  34|         Apprentice|      null| 55000|\n",
      "|  May Mackency|  29|            Diploma|         5| 39000|\n",
      "| Edwards Colin|  26|         Apprentice|         3| 31000|\n",
      "|  Megan Guydry|null|University Graduate|        12| 72000|\n",
      "|Raymon Almeida|  25|            Diploma|         2| 26500|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Discover the row and column which contains null values\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51c31c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+------+\n",
      "|          Name| Age|      Qualification|Salary|\n",
      "+--------------+----+-------------------+------+\n",
      "|Kennith Kawaki|null|            Diploma|  null|\n",
      "|   Sudans Wong|  31|         Apprentice| 40000|\n",
      "|   Polly Combo|  27|            Diploma| 35000|\n",
      "|Desmond Cheung|  51|University Graduate| 88000|\n",
      "|     Chariotte|  35|            Diploma| 61000|\n",
      "|        Sophia|null|         Apprentice| 30000|\n",
      "|          null|  25|            Diploma| 28000|\n",
      "|  George Woody|  31|               null| 47000|\n",
      "|    Pansy Rose|  33|         Apprentice|  null|\n",
      "|          John|  17|         Apprentice| 24300|\n",
      "|         Peter|  45|University Graduate| 81000|\n",
      "|         David|  42|University Graduate| 76000|\n",
      "|        Usamha|  28|            Diploma| 33000|\n",
      "|    Zain Amjun|  34|         Apprentice| 55000|\n",
      "|  May Mackency|  29|            Diploma| 39000|\n",
      "| Edwards Colin|  26|         Apprentice| 31000|\n",
      "|  Megan Guydry|null|University Graduate| 72000|\n",
      "|Raymon Almeida|  25|            Diploma| 26500|\n",
      "+--------------+----+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop a specified column 'Experience'\n",
    "df_spark.drop('Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "576f0168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----------+------+\n",
      "|          Name| Age|      Qualification|Experience|Salary|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "|   Sudans Wong|  31|         Apprentice|         6| 40000|\n",
      "|   Polly Combo|  27|            Diploma|         4| 35000|\n",
      "|Desmond Cheung|  51|University Graduate|        22| 88000|\n",
      "|     Chariotte|  35|            Diploma|         8| 61000|\n",
      "|        Sophia|null|         Apprentice|         3| 30000|\n",
      "|          null|  25|            Diploma|         3| 28000|\n",
      "|  George Woody|  31|               null|         7| 47000|\n",
      "|    Pansy Rose|  33|         Apprentice|      null|  null|\n",
      "|          John|  17|         Apprentice|         1| 24300|\n",
      "|         Peter|  45|University Graduate|        18| 81000|\n",
      "|         David|  42|University Graduate|        15| 76000|\n",
      "|        Usamha|  28|            Diploma|         4| 33000|\n",
      "|    Zain Amjun|  34|         Apprentice|      null| 55000|\n",
      "|  May Mackency|  29|            Diploma|         5| 39000|\n",
      "| Edwards Colin|  26|         Apprentice|         3| 31000|\n",
      "|  Megan Guydry|null|University Graduate|        12| 72000|\n",
      "|Raymon Almeida|  25|            Diploma|         2| 26500|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the row contain NULL value\n",
    "# df_spark.na.drop(how='any', thresh=3).show().\n",
    "# Drop rows wiht non-null value less than thresh=3\n",
    "# i.e. Two non-null value in the first record \n",
    "# which Name is 'Kennith Kawaki' will be dropped\n",
    "df_spark.dropna(how='any', thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3717cda5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+-------------------+----------+------+\n",
      "|          Name|Age|      Qualification|Experience|Salary|\n",
      "+--------------+---+-------------------+----------+------+\n",
      "|   Sudans Wong| 31|         Apprentice|         6| 40000|\n",
      "|   Polly Combo| 27|            Diploma|         4| 35000|\n",
      "|Desmond Cheung| 51|University Graduate|        22| 88000|\n",
      "|     Chariotte| 35|            Diploma|         8| 61000|\n",
      "|          John| 17|         Apprentice|         1| 24300|\n",
      "|         Peter| 45|University Graduate|        18| 81000|\n",
      "|         David| 42|University Graduate|        15| 76000|\n",
      "|        Usamha| 28|            Diploma|         4| 33000|\n",
      "|  May Mackency| 29|            Diploma|         5| 39000|\n",
      "| Edwards Colin| 26|         Apprentice|         3| 31000|\n",
      "|Raymon Almeida| 25|            Diploma|         2| 26500|\n",
      "+--------------+---+-------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the row contain NULL value\n",
    "# df_spark.na.drop(how='any', thresh=3).show()\n",
    "df_spark.na.drop(how='any').show()  # result of df_spark.dropna(how='any').show() is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1816b59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----------+------+\n",
      "|          Name| Age|      Qualification|Experience|Salary|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "|Kennith Kawaki|null|            Diploma|      null|  null|\n",
      "|   Sudans Wong|  31|         Apprentice|         6| 40000|\n",
      "|   Polly Combo|  27|            Diploma|         4| 35000|\n",
      "|Desmond Cheung|  51|University Graduate|        22| 88000|\n",
      "|     Chariotte|  35|            Diploma|         8| 61000|\n",
      "|        Sophia|null|         Apprentice|         3| 30000|\n",
      "|  George Woody|  31|               null|         7| 47000|\n",
      "|    Pansy Rose|  33|         Apprentice|      null|  null|\n",
      "|          John|  17|         Apprentice|         1| 24300|\n",
      "|         Peter|  45|University Graduate|        18| 81000|\n",
      "|         David|  42|University Graduate|        15| 76000|\n",
      "|        Usamha|  28|            Diploma|         4| 33000|\n",
      "|    Zain Amjun|  34|         Apprentice|      null| 55000|\n",
      "|  May Mackency|  29|            Diploma|         5| 39000|\n",
      "| Edwards Colin|  26|         Apprentice|         3| 31000|\n",
      "|  Megan Guydry|null|University Graduate|        12| 72000|\n",
      "|Raymon Almeida|  25|            Diploma|         2| 26500|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the Subset row contain NULL value\n",
    "df_spark.na.drop(how='any', subset=['Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18ac920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----------+------+\n",
      "|          Name| Age|      Qualification|Experience|Salary|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "|Kennith Kawaki|null|            Diploma|      null|  null|\n",
      "|   Sudans Wong|  31|         Apprentice|         6| 40000|\n",
      "|   Polly Combo|  27|            Diploma|         4| 35000|\n",
      "|Desmond Cheung|  51|University Graduate|        22| 88000|\n",
      "|     Chariotte|  35|            Diploma|         8| 61000|\n",
      "|        Sophia|null|         Apprentice|         3| 30000|\n",
      "|   Missing One|  25|            Diploma|         3| 28000|\n",
      "|  George Woody|  31|        Missing One|         7| 47000|\n",
      "|    Pansy Rose|  33|         Apprentice|      null|  null|\n",
      "|          John|  17|         Apprentice|         1| 24300|\n",
      "|         Peter|  45|University Graduate|        18| 81000|\n",
      "|         David|  42|University Graduate|        15| 76000|\n",
      "|        Usamha|  28|            Diploma|         4| 33000|\n",
      "|    Zain Amjun|  34|         Apprentice|      null| 55000|\n",
      "|  May Mackency|  29|            Diploma|         5| 39000|\n",
      "| Edwards Colin|  26|         Apprentice|         3| 31000|\n",
      "|  Megan Guydry|null|University Graduate|        12| 72000|\n",
      "|Raymon Almeida|  25|            Diploma|         2| 26500|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the dataframe\n",
    "df_spark=spark.read.csv('test3.csv', header=True, inferSchema=True)\n",
    "\n",
    "## Fill the missing value\n",
    "## Because the read csv file applies inferSchema=True\n",
    "## Thus all the string field contains null value will be filled with 'Missing One'\n",
    "df_spark.na.fill('Missing One').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf89c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-------------------+-----------+------+\n",
      "|          Name|        Age|      Qualification| Experience|Salary|\n",
      "+--------------+-----------+-------------------+-----------+------+\n",
      "|Kennith Kawaki|Missing One|            Diploma|Missing One|  null|\n",
      "|   Sudans Wong|         31|         Apprentice|          6| 40000|\n",
      "|   Polly Combo|         27|            Diploma|          4| 35000|\n",
      "|Desmond Cheung|         51|University Graduate|         22| 88000|\n",
      "|     Chariotte|         35|            Diploma|          8| 61000|\n",
      "|        Sophia|Missing One|         Apprentice|          3| 30000|\n",
      "|          null|         25|            Diploma|          3| 28000|\n",
      "|  George Woody|         31|               null|          7| 47000|\n",
      "|    Pansy Rose|         33|         Apprentice|Missing One|  null|\n",
      "|          John|         17|         Apprentice|          1| 24300|\n",
      "|         Peter|         45|University Graduate|         18| 81000|\n",
      "|         David|         42|University Graduate|         15| 76000|\n",
      "|        Usamha|         28|            Diploma|          4| 33000|\n",
      "|    Zain Amjun|         34|         Apprentice|Missing One| 55000|\n",
      "|  May Mackency|         29|            Diploma|          5| 39000|\n",
      "| Edwards Colin|         26|         Apprentice|          3| 31000|\n",
      "|  Megan Guydry|Missing One|University Graduate|         12| 72000|\n",
      "|Raymon Almeida|         25|            Diploma|          2| 26500|\n",
      "+--------------+-----------+-------------------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the dataframe\n",
    "df_spark=spark.read.csv('test3.csv', header=True, inferSchema=False)\n",
    "\n",
    "## Fill the missing value\n",
    "df_spark.na.fill('Missing One', ['Age', 'Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3faf3fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----------+------+\n",
      "|          Name| Age|      Qualification|Experience|Salary|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "|Kennith Kawaki|null|            Diploma|      null|  null|\n",
      "|   Sudans Wong|  31|         Apprentice|         6| 40000|\n",
      "|   Polly Combo|  27|            Diploma|         4| 35000|\n",
      "|Desmond Cheung|  51|University Graduate|        22| 88000|\n",
      "|     Chariotte|  35|            Diploma|         8| 61000|\n",
      "|        Sophia|null|         Apprentice|         3| 30000|\n",
      "|          null|  25|            Diploma|         3| 28000|\n",
      "|  George Woody|  31|               null|         7| 47000|\n",
      "|    Pansy Rose|  33|         Apprentice|      null|  null|\n",
      "|          John|  17|         Apprentice|         1| 24300|\n",
      "|         Peter|  45|University Graduate|        18| 81000|\n",
      "|         David|  42|University Graduate|        15| 76000|\n",
      "|        Usamha|  28|            Diploma|         4| 33000|\n",
      "|    Zain Amjun|  34|         Apprentice|      null| 55000|\n",
      "|  May Mackency|  29|            Diploma|         5| 39000|\n",
      "| Edwards Colin|  26|         Apprentice|         3| 31000|\n",
      "|  Megan Guydry|null|University Graduate|        12| 72000|\n",
      "|Raymon Almeida|  25|            Diploma|         2| 26500|\n",
      "+--------------+----+-------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Read the dataframe\n",
    "df_spark=spark.read.csv('test3.csv', header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Since we cannot take mean on 'Name' field, so just 'Age', 'Experience' and 'Salary' can be\n",
    "# Applied imputer...\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age', 'Experience', 'Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
    "    ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4738cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------------------+----------+------+-----------+------------------+--------------+\n",
      "|          Name| Age|      Qualification|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------------+----+-------------------+----------+------+-----------+------------------+--------------+\n",
      "|Kennith Kawaki|null|            Diploma|      null|  null|         31|                 7|         47925|\n",
      "|   Sudans Wong|  31|         Apprentice|         6| 40000|         31|                 6|         40000|\n",
      "|   Polly Combo|  27|            Diploma|         4| 35000|         27|                 4|         35000|\n",
      "|Desmond Cheung|  51|University Graduate|        22| 88000|         51|                22|         88000|\n",
      "|     Chariotte|  35|            Diploma|         8| 61000|         35|                 8|         61000|\n",
      "|        Sophia|null|         Apprentice|         3| 30000|         31|                 3|         30000|\n",
      "|          null|  25|            Diploma|         3| 28000|         25|                 3|         28000|\n",
      "|  George Woody|  31|               null|         7| 47000|         31|                 7|         47000|\n",
      "|    Pansy Rose|  33|         Apprentice|      null|  null|         33|                 7|         47925|\n",
      "|          John|  17|         Apprentice|         1| 24300|         17|                 1|         24300|\n",
      "|         Peter|  45|University Graduate|        18| 81000|         45|                18|         81000|\n",
      "|         David|  42|University Graduate|        15| 76000|         42|                15|         76000|\n",
      "|        Usamha|  28|            Diploma|         4| 33000|         28|                 4|         33000|\n",
      "|    Zain Amjun|  34|         Apprentice|      null| 55000|         34|                 7|         55000|\n",
      "|  May Mackency|  29|            Diploma|         5| 39000|         29|                 5|         39000|\n",
      "| Edwards Colin|  26|         Apprentice|         3| 31000|         26|                 3|         31000|\n",
      "|  Megan Guydry|null|University Graduate|        12| 72000|         31|                12|         72000|\n",
      "|Raymon Almeida|  25|            Diploma|         2| 26500|         25|                 2|         26500|\n",
      "+--------------+----+-------------------+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation columns (插補列) to df\n",
    "imputer.fit(df_spark).transform(df_spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853543d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
