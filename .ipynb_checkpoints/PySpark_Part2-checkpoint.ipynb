{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e55fe2",
   "metadata": {},
   "source": [
    "# Lesson Two : Introduction to Pyspark\n",
    "### By Samuel Ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21cce014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To investigate the use of the Pyspark SQL statements and other functions\n",
    "# By Samuel Ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af4d4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afe941f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SparkSession to create DataFrame,\n",
    "# and execute SQL commands over tables, cache tables, and read parquet files\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "570c4e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session for operation\n",
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c83e2e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.2.85:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x110b94a30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4a5e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data set into dataframe\n",
    "df_pyspark=spark.read.option('header','true').csv('test2.csv',inferSchema=True)\n",
    "\n",
    "# With InferSchema Option = True:\n",
    "# Infer schema will automatically guess the data types for each field. \n",
    "# If we set this option to TRUE, the API will read some sample records \n",
    "# from the file to infer the schema. If we want to set this value to false, \n",
    "# ****We must specify a schema explicitly****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ca57960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Year_Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine the true table schema (with exact data type)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22d01a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now Check the type of the pyspark dataframe (dataframe means data structure)\n",
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0021e193",
   "metadata": {},
   "source": [
    "### As we can see the dataframe of pyspark is different from the dataframe of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c40a57e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Year_Experience']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to display the column name \n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "affdf0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To select a specific column from dataframe to display, use\n",
    "df_pyspark.select('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e998f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|          Name|Year_Experience|\n",
      "+--------------+---------------+\n",
      "|Kennith Kawaki|              7|\n",
      "|   Sudans Wong|              6|\n",
      "|   Polly Combo|              4|\n",
      "|Desmond Cheung|             22|\n",
      "|     Chariotte|              8|\n",
      "|        Sophia|              3|\n",
      "|          John|              3|\n",
      "|  George Woody|              7|\n",
      "|    Pansy Rose|              9|\n",
      "|          John|              1|\n",
      "|         Peter|             18|\n",
      "|         David|             15|\n",
      "|        Usamha|              4|\n",
      "|          Zain|              7|\n",
      "+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the select statement\n",
    "df_pyspark.select('Name','Year_Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "731360cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df85b323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Year_Experience', 'int')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the datatype of the table\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed7ea9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+-----------------+\n",
      "|summary|     Name|               Age|  Year_Experience|\n",
      "+-------+---------+------------------+-----------------+\n",
      "|  count|       14|                14|               14|\n",
      "|   mean|     null|32.642857142857146|8.142857142857142|\n",
      "| stddev|     null| 8.793416618367164|6.099900917948685|\n",
      "|    min|Chariotte|                17|                1|\n",
      "|    max|     Zain|                51|               22|\n",
      "+-------+---------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .describe() function to calculate the summary statistics of \n",
    "# columns present in the DataFrame\n",
    "# such as 1) Count, 2) Mean, 3) Stddev, 4) Min and 5) Max\n",
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b99bfd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the calculated columns in dataframe\n",
    "df_pyspark=df_pyspark.withColumn('Experience_After_5_Yrs', df_pyspark['Year_Experience']+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cd57cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---------------+----------------------+\n",
      "|          Name|Age|Year_Experience|Experience_After_5_Yrs|\n",
      "+--------------+---+---------------+----------------------+\n",
      "|Kennith Kawaki| 33|              7|                    12|\n",
      "|   Sudans Wong| 31|              6|                    11|\n",
      "|   Polly Combo| 27|              4|                     9|\n",
      "|Desmond Cheung| 51|             22|                    27|\n",
      "|     Chariotte| 35|              8|                    13|\n",
      "|        Sophia| 25|              3|                     8|\n",
      "|          John| 25|              3|                     8|\n",
      "|  George Woody| 31|              7|                    12|\n",
      "|    Pansy Rose| 33|              9|                    14|\n",
      "|          John| 17|              1|                     6|\n",
      "|         Peter| 45|             18|                    23|\n",
      "|         David| 42|             15|                    20|\n",
      "|        Usamha| 28|              4|                     9|\n",
      "|          Zain| 34|              7|                    12|\n",
      "+--------------+---+---------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5ec920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, drop the unwanted column\n",
    "df_pyspark=df_pyspark.drop('Experience_After_5_Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78ebaa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---------------+\n",
      "|          Name|Age|Year_Experience|\n",
      "+--------------+---+---------------+\n",
      "|Kennith Kawaki| 33|              7|\n",
      "|   Sudans Wong| 31|              6|\n",
      "|   Polly Combo| 27|              4|\n",
      "|Desmond Cheung| 51|             22|\n",
      "|     Chariotte| 35|              8|\n",
      "|        Sophia| 25|              3|\n",
      "|          John| 25|              3|\n",
      "|  George Woody| 31|              7|\n",
      "|    Pansy Rose| 33|              9|\n",
      "|          John| 17|              1|\n",
      "|         Peter| 45|             18|\n",
      "|         David| 42|             15|\n",
      "|        Usamha| 28|              4|\n",
      "|          Zain| 34|              7|\n",
      "+--------------+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8749e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+----------+\n",
      "|          Name|Age|Experience|\n",
      "+--------------+---+----------+\n",
      "|Kennith Kawaki| 33|         7|\n",
      "|   Sudans Wong| 31|         6|\n",
      "|   Polly Combo| 27|         4|\n",
      "|Desmond Cheung| 51|        22|\n",
      "|     Chariotte| 35|         8|\n",
      "|        Sophia| 25|         3|\n",
      "|          John| 25|         3|\n",
      "|  George Woody| 31|         7|\n",
      "|    Pansy Rose| 33|         9|\n",
      "|          John| 17|         1|\n",
      "|         Peter| 45|        18|\n",
      "|         David| 42|        15|\n",
      "|        Usamha| 28|         4|\n",
      "|          Zain| 34|         7|\n",
      "+--------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To rename a column \"Year_Experience\" to \"Experience\"\n",
    "df_temp = df_pyspark.withColumnRenamed('Year_Experience','Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13378b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
